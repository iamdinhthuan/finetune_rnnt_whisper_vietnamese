# Whisper RNN-T: Vietnamese Speech Recognition

A streaming Vietnamese speech recognition system combining Whisper encoder with RNN-T decoder for real-time transcription.

## Features

- ğŸ¯ **Step-based Model Saving**: Automatic checkpoint saving every N steps with WER-based selection
- ğŸ”„ **Streaming Recognition**: Real-time audio processing with streaming RNN-T decoder
- ğŸ›ï¸ **Whisper Base Encoder**: Pre-trained Whisper Base encoder for robust feature extraction
- ğŸ‡»ğŸ‡³ **Vietnamese Optimized**: Trained specifically for Vietnamese speech recognition
- ğŸ’¾ **Smart Storage**: Saves only model weights, keeps top-K best models automatically
- ğŸ“Š **Comprehensive Logging**: Detailed training metrics and model performance tracking

## Architecture

```
Audio Input â†’ Whisper Encoder â†’ RNN-T Decoder â†’ Vietnamese Text
```

- **Encoder**: Whisper Base (6 layers, 512 dim, 8 heads)
- **Decoder**: LSTM-based RNN-T decoder
- **Joint Network**: Projects encoder-decoder outputs to vocabulary space
- **Loss**: RNN-T loss with blank token handling

## Model Saving Strategy

The system implements intelligent step-based model saving:

- âœ… **Save every N steps** (configurable, default: 1000)
- âœ… **Keep top-K models** based on validation WER (default: 3)
- âœ… **Automatic cleanup** of worse-performing models
- âœ… **Weights-only saving** to reduce storage
- âœ… **Fallback mechanism** using train_loss when val_wer unavailable

## Installation

```bash
# Clone repository
git clone <your-repo-url>
cd whisper_rnnt

# Install dependencies
pip install torch pytorch-lightning
pip install librosa sentencepiece
pip install warprnnt-numba
pip install loguru tqdm
pip install gradio  # for UI demo
```

## Quick Start

### 1. Download Pre-trained Weights

```bash
cd weights
python download_whisper_base.py
python export_encoder.py
```

### 2. Training

```bash
# Configure your data paths in config.yaml
python train.py
```

### 3. Real-time Demo

```bash
python infer_stream_ui.py
```

## Configuration

Edit `config.yaml` to customize:

```yaml
# Model saving strategy
model_saving:
  save_every_n_steps: 1000  # Save frequency
  keep_top_k: 3            # Number of best models to keep
  monitor_metric: 'val_wer' # Metric for model selection
  save_weights_only: true   # Save only weights
```

## Training Features

- **Step-based validation**: Runs validation every N steps instead of epochs
- **Automatic model selection**: Keeps only the best performing models
- **Comprehensive metrics**: WER, loss tracking with detailed logging
- **Memory efficient**: Saves only model weights, not full checkpoints
- **Robust training**: Handles missing metrics with fallback mechanisms

## File Structure

```
whisper_rnnt/
â”œâ”€â”€ config.yaml              # Configuration file
â”œâ”€â”€ train.py                 # Training script
â”œâ”€â”€ infer_stream_ui.py       # Gradio demo
â”œâ”€â”€ models/                  # Model architectures
â”‚   â”œâ”€â”€ encoder.py          # Whisper encoder
â”‚   â”œâ”€â”€ decoder.py          # RNN-T decoder
â”‚   â””â”€â”€ jointer.py          # Joint network
â”œâ”€â”€ utils/                   # Utilities
â”‚   â”œâ”€â”€ model_checkpoint.py # Step-based saving
â”‚   â”œâ”€â”€ dataset.py          # Data loading
â”‚   â””â”€â”€ scheduler.py        # Learning rate scheduling
â””â”€â”€ weights/                 # Model weights
    â”œâ”€â”€ download_whisper_base.py
```

## Model Performance

The step-based saving system ensures you always have access to the best performing models:

- Models are saved with descriptive filenames: `rnnt-step-001000-wer-0.1234.pt`
- Automatic cleanup removes worse-performing checkpoints
- Detailed metrics tracking in `model_metrics.json`

## Contributing

1. Fork the repository
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## License

This project is licensed under the MIT License.

## Acknowledgments

- OpenAI Whisper for the pre-trained encoder
- PyTorch Lightning for training framework
- RNN-T implementation from warprnnt-numba
